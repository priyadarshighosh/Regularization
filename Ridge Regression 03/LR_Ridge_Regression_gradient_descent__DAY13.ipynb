{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Ridge Regression  - Gradient Descent\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "u93QB4H8gs0F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORTING DATA SCIENCE LIBRARIES"
      ],
      "metadata": {
        "id": "I2xjrloHcxJQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JF9RMWnFZYq3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORT MACHINE LEARNING LIBRARIES AND CLASSES"
      ],
      "metadata": {
        "id": "-FDeOVL3M7rU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split               #for splitting the data into test and training data\n",
        "from sklearn.compose import ColumnTransformer                       #for transforming the columns\n",
        "from sklearn.impute import SimpleImputer                             #for imputing the missing values\n",
        "from sklearn.preprocessing import OneHotEncoder                      #one hot encoding\n",
        "from sklearn.preprocessing import MinMaxScaler                        #standard scaling\n",
        "\n",
        "from sklearn.datasets import load_diabetes\n",
        "\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score                 # for accuracy score\n",
        "from sklearn.model_selection import cross_val_score        # for cross validation score\n",
        "\n",
        "from sklearn.linear_model import LinearRegression           # Import the LinearRegression class\n",
        "from sklearn.metrics import mean_squared_error, r2_score    # to find out the error functions\n",
        "from sklearn.preprocessing import PolynomialFeatures , StandardScaler   # for the polunomial features\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import Ridge   # ridge Regression"
      ],
      "metadata": {
        "id": "Y208GDIXgEai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading and Information about the Dataset"
      ],
      "metadata": {
        "id": "XTPRT3iy9EuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "diabetes = load_diabetes()\n",
        "\n",
        "X , y = diabetes.data , diabetes.target"
      ],
      "metadata": {
        "id": "PAXRZRNaJVKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Train and test split"
      ],
      "metadata": {
        "id": "DReLCuu6HhrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train , X_test , y_train , y_test = train_test_split(X , y , test_size = 0.2 , random_state = 4)"
      ],
      "metadata": {
        "id": "fP3lgmCwHk0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Applying Ridge Class in Gradient Descent ( that L2 Parameter )"
      ],
      "metadata": {
        "id": "qCZZvhV3Idkh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model  import SGDRegressor"
      ],
      "metadata": {
        "id": "G37tF2tRl8xz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg = SGDRegressor(penalty='l2', max_iter=500 , eta0 =0.1 , learning_rate='constant' , alpha= 0.001)\n",
        "reg.fit(X_train , y_train)"
      ],
      "metadata": {
        "id": "6ti9obfmIdHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Penalty - Regularization type L2 - Ridge Regression\n",
        "max_iteration - Basically epoch\n",
        "\n",
        "eta0 - Initital value of the learning\n",
        "\n",
        "learning rate - gonna be constant\n",
        "alpha is the regularization constant - lamda(m sq )"
      ],
      "metadata": {
        "id": "qJ0OHUpRniap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = reg.predict(X_test)\n",
        "r2_score(y_test , y_pred)"
      ],
      "metadata": {
        "id": "ezG_gb3tIsY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"reg.coef : \" , reg.coef_)\n",
        "print (\"reg.intercept : \" , reg.intercept_)"
      ],
      "metadata": {
        "id": "bj56gDYEJBSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Applying gradient Descent in the  Ridge Class"
      ],
      "metadata": {
        "id": "kXgmmBe6omiu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "reg = Ridge(alpha=0.001 , max_iter=500 , solver='sparse_cg')"
      ],
      "metadata": {
        "id": "AlhDsYMyqSYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Solver is"
      ],
      "metadata": {
        "id": "zgxbuOM8qVR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reg.fit(X_train , y_train)\n",
        "r2_score(y_test , y_pred)"
      ],
      "metadata": {
        "id": "VfmMLtPNpWWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"reg.coef : \" , reg.coef_)\n",
        "print (\"reg.intercept : \" , reg.intercept_)"
      ],
      "metadata": {
        "id": "dt5_A7nApdKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Making our Own Gradient Descent Class for Ridge Regression"
      ],
      "metadata": {
        "id": "9BRPfdeSJ6Vt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RidgeGradientDescent:\n",
        "\n",
        "  def __init__(self ,epochs ,learning_rate ,  alpha=0.1 ):\n",
        "\n",
        "    self.learning_rate = learning_rate\n",
        "    self.epochs = epochs\n",
        "    self.alpha = alpha\n",
        "    self.weights = None\n",
        "    self.bias = None\n",
        "\n",
        "  def fit(self , X_train , y_train):\n",
        "\n",
        "    self.coef_ = np.ones(X_train.shape[1])\n",
        "    self.intercept_ = 0                 # initial intercept is 0\n",
        "    theta = np.insert(self.coef_ , 0 , self.intercept_)  # this theta is the initial value\n",
        "\n",
        "\n",
        "    X_train = np.insert(X_train , 0 , 1 , axis =1  )\n",
        "\n",
        "    for i in range(self.epochs):           # Gradient Descent Using loop\n",
        "        theta_der = np.dot(X_train.T , X_train).dot(theta) - np.dot(X_train.T , y_train) + self.alpha * theta\n",
        "        theta = theta - self.learning_rate * theta_der  # updating the theta value\n",
        "\n",
        "    self.intercept_ = theta[0]   # 1st value the theta is B0 that is interept\n",
        "    self.coef_ = theta[1:]     # from B1 , B2 ... Bn are the changed value of the weights\n",
        "\n",
        "  def predict(self , X_test):\n",
        "    return np.dot(X_test , self.coef_) + self.intercept_      #predicted value of  y - Y_pred"
      ],
      "metadata": {
        "id": "3YDf0qh4vWor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fitting the value of X and y into the Ridge Regression ( Just changing the value of alpha , learning rate and epochs )"
      ],
      "metadata": {
        "id": "AF37ngnB-z7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reg = RidgeGradientDescent(epochs=500 ,alpha = 5, learning_rate=0.001 )\n",
        "reg.fit(X_train , y_train)\n",
        "\n",
        "y_pred = reg.predict(X_test)\n",
        "r2_score(y_test , y_pred)\n",
        "\n",
        "print(\"reg.coef : \" , reg.coef_)\n",
        "print(\"reg.intercept : \" , reg.intercept_)\n",
        "\n",
        "print(\"R2:\", r2_score(y_test , y_pred) )\n"
      ],
      "metadata": {
        "id": "UZgerMGA-zU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg2 = RidgeGradientDescent(epochs=250 ,alpha = 25, learning_rate=0.01 )\n",
        "reg2.fit(X_train , y_train)\n",
        "\n",
        "y_pred = reg2.predict(X_test)\n",
        "r2_score(y_test , y_pred)\n",
        "\n",
        "print(\"reg.coef : \" , reg2.coef_)\n",
        "print(\"reg.intercept : \" , reg2.intercept_)\n",
        "\n",
        "print(\"R2:\", r2_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "CxPBPoyDBOBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg3 = RidgeGradientDescent(epochs=100 ,alpha = 50, learning_rate=0.1 )\n",
        "reg3.fit(X_train , y_train )\n",
        "\n",
        "y_pred = reg3.predict(X_test)\n",
        "r2_score(y_test , y_pred)\n",
        "\n",
        "print(\"reg.coef : \" , reg3.coef_)\n",
        "print(\"reg.intercept : \" , reg3.intercept_)\n",
        "\n",
        "print(\"R2:\", r2_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "L30c72MSBOg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg4 = RidgeGradientDescent(epochs=50 ,alpha = 100, learning_rate=1 )\n",
        "reg4.fit(X_train , y_train)\n",
        "\n",
        "y_pred = reg4.predict(X_test)\n",
        "r2_score(y_test , y_pred)\n",
        "\n",
        "print(\"reg.coef : \" , reg4.coef_)\n",
        "print(\"reg.intercept : \" , reg4.intercept_)\n",
        "\n",
        "print(\"R2:\", r2_score(y_test, y_pred) )"
      ],
      "metadata": {
        "id": "axIXhXmNBP3z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}