{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Ridge Regression\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "u93QB4H8gs0F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORTING DATA SCIENCE LIBRARIES"
      ],
      "metadata": {
        "id": "I2xjrloHcxJQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JF9RMWnFZYq3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORT MACHINE LEARNING LIBRARIES AND CLASSES"
      ],
      "metadata": {
        "id": "-FDeOVL3M7rU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split               #for splitting the data into test and training data\n",
        "from sklearn.compose import ColumnTransformer                       #for transforming the columns\n",
        "from sklearn.impute import SimpleImputer                             #for imputing the missing values\n",
        "from sklearn.preprocessing import OneHotEncoder                      #one hot encoding\n",
        "from sklearn.preprocessing import MinMaxScaler                        #standard scaling\n",
        "\n",
        "from sklearn.datasets import load_diabetes\n",
        "\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score                 # for accuracy score\n",
        "from sklearn.model_selection import cross_val_score        # for cross validation score\n",
        "\n",
        "from sklearn.linear_model import LinearRegression # Import the LinearRegression class\n",
        "from sklearn.metrics import mean_squared_error, r2_score    # to find out the error functions\n",
        "from sklearn.preprocessing import PolynomialFeatures , StandardScaler   # for the polunomial features\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import Ridge   # ridge Regression"
      ],
      "metadata": {
        "id": "Y208GDIXgEai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading and Information about the Dataset"
      ],
      "metadata": {
        "id": "XTPRT3iy9EuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = 100\n",
        "x1 = 5*np.random.rand(m,1) - 2\n",
        "x2 = 0.7*x1**2 - 2*x1 + 1 + np.random.randn(m,1)\n",
        "\n",
        "plt.scatter(x1,x2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PAXRZRNaJVKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train , X_test , y_train , y_test = train_test_split(x1 , x2 , test_size=0.2 , random_state=2)  # splitting the data into test and training data"
      ],
      "metadata": {
        "id": "KXTH__L2fIV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression"
      ],
      "metadata": {
        "id": "TXpeuuZreukF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reg = LinearRegression()\n",
        "reg.fit(X_train, y_train)   # fitting the data"
      ],
      "metadata": {
        "id": "1_eHQIdvexrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (reg.coef_)\n",
        "print (reg.intercept_)"
      ],
      "metadata": {
        "id": "FzyBNnlRfbj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = reg.predict(X_test)      # predicting the y value from x test value  from training the data\n",
        "r2_score(y_test, y_pred)         # calculating the r2 score\n",
        "print(\"R2 Score\",r2_score(y_test , y_pred))\n",
        "print(\"RMSE \" , np.sqrt(mean_squared_error(y_test,y_pred)))"
      ],
      "metadata": {
        "id": "KdHbkEmPf4hD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ridge Regression with Polynomials"
      ],
      "metadata": {
        "id": "XF8WK_y3F02B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basically We added alpha the regularization term so that we can do Ridge Regularization that is our L2 regularization"
      ],
      "metadata": {
        "id": "feDY97-TQzO2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "def get_preds_ridge(x1 , x2 , alpha):\n",
        "\n",
        "   model = Pipeline([\n",
        "\n",
        "       ('poly',PolynomialFeatures(degree=16)) ,\n",
        "       ('ridge',Ridge(alpha=alpha))\n",
        "\n",
        "   ])\n",
        "\n",
        "   model.fit(x1,x2)\n",
        "   return model.predict(x1)"
      ],
      "metadata": {
        "id": "sviXhiKvKKkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Plotting the figure with 3 different values of Alpha"
      ],
      "metadata": {
        "id": "h4SqDwOQK-9m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to have a Red line when our alpha gonna be 0 that is no regularization , we gonna have Green curve when alpha gonna be 20  and we gonna have a blue curve when our alpha gonna be 200"
      ],
      "metadata": {
        "id": "hLoulJ6tL4ev"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is to show that how the trajectory of our line changes when we increase or decrease the value of alpha"
      ],
      "metadata": {
        "id": "FycWqJ7mMIHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting the data points\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.plot(x1,x2,'b.', label='Datapoints')\n",
        "plt.xlabel('x1')\n",
        "plt.ylabel('x2')\n"
      ],
      "metadata": {
        "id": "l1ocIXyLLCjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are plotting the datapoints with our 3 colorful curves for the 3 values of alpha ."
      ],
      "metadata": {
        "id": "J4fwqPQKMqbs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alphas = [ 0 , 20 , 200]\n",
        "cs = ['r' , 'g' , 'b']\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.plot(x1,x2,'b.', label='Datapoints')\n",
        "plt.xlabel('x1')\n",
        "plt.ylabel('x2')\n",
        "\n",
        "\n",
        "for alpha , c in zip(alphas , cs ):\n",
        "   preds = get_preds_ridge(x1 , x2 , alpha)\n",
        "\n",
        "   # plot\n",
        "   plt.plot(sorted(x1[:,0]), preds[np.argsort(x1[:,0])] , c , label=f'Alpha = {alpha}')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()\n",
        ""
      ],
      "metadata": {
        "id": "RuDUas1pLeHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above diagram we can see that blue curve has less curve its just going with the flow , in that cruve only we have the MAximum regularization / alpha value maximum as 200  [ UNDERFITTING ]\n",
        "\n",
        "Red Curve is turning too much that it it has regularization value  / alpha value as 0 [ OVERFITTING ]\n",
        "\n",
        "Green Curve is perfect balance between the Blue Curve and Red curve ."
      ],
      "metadata": {
        "id": "Qji0wRiWPdbn"
      }
    }
  ]
}